
<!DOCTYPE html><html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.33.1" theme-name="Stellar" theme-version="1.33.1">
  
  
  <meta name="generator" content="Hexo 6.3.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000">
  <meta name="theme-color" content="#f9fafb">
  <title>GAN - Caiusçš„æ—¥å¸¸åšå®¢</title>

  
    <meta name="description" content="å¯¹æŠ—ç”Ÿæˆç½‘ç»œ GAN(Generative Adversarial Nets) Adversarial Nets Framework ç”Ÿæˆå™¨ä¸åˆ¤åˆ«å™¨çŠ¶æ€ç›¸ç­‰ æŸå¤±å‡½æ•°å®ƒåšçš„æ˜¯å»æœ€å¤§åŒ– Dçš„åŒºåˆ†åº¦ï¼Œæœ€å°åŒ–Gå’Œrealæ•°æ®é›†çš„æ•°æ®åˆ†å¸ƒ åˆ¤åˆ«æ¨¡å‹ï¼š D1 å’Œ D2 ç›¸åŒçš„ï¼Œæ˜¯åˆ¤åˆ«å™¨ï¼ŒGæ˜¯ç”Ÿæˆå™¨ ç”Ÿæˆæ¨¡å‹ï¼š å…ˆè®­ç»ƒåˆ¤åˆ«å™¨ï¼Œåœ¨è®­ç»ƒç”Ÿæˆå™¨ã€‚ 1   2   3   4   5   6   7   8   9">
<meta property="og:type" content="article">
<meta property="og:title" content="GAN">
<meta property="og:url" content="https://caiusy.github.io/2019/11/26/GAN/">
<meta property="og:site_name" content="Caiusçš„æ—¥å¸¸åšå®¢">
<meta property="og:description" content="å¯¹æŠ—ç”Ÿæˆç½‘ç»œ GAN(Generative Adversarial Nets) Adversarial Nets Framework ç”Ÿæˆå™¨ä¸åˆ¤åˆ«å™¨çŠ¶æ€ç›¸ç­‰ æŸå¤±å‡½æ•°å®ƒåšçš„æ˜¯å»æœ€å¤§åŒ– Dçš„åŒºåˆ†åº¦ï¼Œæœ€å°åŒ–Gå’Œrealæ•°æ®é›†çš„æ•°æ®åˆ†å¸ƒ åˆ¤åˆ«æ¨¡å‹ï¼š D1 å’Œ D2 ç›¸åŒçš„ï¼Œæ˜¯åˆ¤åˆ«å™¨ï¼ŒGæ˜¯ç”Ÿæˆå™¨ ç”Ÿæˆæ¨¡å‹ï¼š å…ˆè®­ç»ƒåˆ¤åˆ«å™¨ï¼Œåœ¨è®­ç»ƒç”Ÿæˆå™¨ã€‚ 1   2   3   4   5   6   7   8   9">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://caiusy.github.io/images/avatar.jpg">
<meta property="article:published_time" content="2019-11-25T16:00:00.000Z">
<meta property="article:modified_time" content="2026-02-20T07:15:58.503Z">
<meta property="article:author" content="Caius Lu">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://caiusy.github.io/images/avatar.jpg">
  
  
  
  <meta name="keywords" content="Python">

  <!-- feed -->
  

  <link rel="stylesheet" href="/css/main.css?v=1.33.1">


  

  

  <script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Caius Lu","sameAs":[],"image":"https://caiusy.github.io/images/avatar.jpg"},"dateCreated":"2019-11-26T00:00:00+08:00","dateModified":"2026-02-20T15:15:58+08:00","datePublished":"2019-11-26T00:00:00+08:00","description":"","headline":"GAN","mainEntityOfPage":{"@type":"WebPage","@id":"https://caiusy.github.io/2019/11/26/GAN/"},"publisher":{"@type":"Organization","name":"Caius Lu","sameAs":[],"image":"https://caiusy.github.io/images/avatar.jpg","logo":{"@type":"ImageObject","url":"https://caiusy.github.io/images/avatar.jpg"}},"url":"https://caiusy.github.io/2019/11/26/GAN/","keywords":"Python","image":[]}</script>
  <link rel="stylesheet" href="/css/custom.css"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<body>

<div class="l_body content" id="start" layout="post" type="tech" ><aside class="l_left"><div class="sidebg"></div><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="/images/avatar.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main">Caiusçš„æ—¥å¸¸åšå®¢</div><div class="sub normal cap">è®¡ç®—æœºè§†è§‰</div><div class="sub hover cap" style="opacity:0"> å¤§æ¨¡å‹åˆå­¦è€…</div></a></div></header>

<div class="nav-area">

<nav class="menu dis-select"><a class="nav-item active" title="åšå®¢" href="/" style="color:#6366F1"><img src="https://api.iconify.design/solar:documents-bold-duotone.svg?color=%236366F1"/></a><a class="nav-item" title="å½’æ¡£" href="/archives/" style="color:#10B981"><img src="https://api.iconify.design/solar:archive-bold-duotone.svg?color=%2310B981"/></a><a class="nav-item" title="åˆ†ç±»" href="/categories/" style="color:#F59E0B"><img src="https://api.iconify.design/solar:folder-with-files-bold-duotone.svg?color=%23F59E0B"/></a><a class="nav-item" title="æ ‡ç­¾" href="/tags/" style="color:#EC4899"><img src="https://api.iconify.design/solar:tag-bold-duotone.svg?color=%23EC4899"/></a></nav>
</div>
<div class="widgets">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="Search"></form><div id="search-result"></div><div class="search-no-result">No Results!</div></div>



<widget class="widget-wrapper slide-up recent post-list"><div class="widget-header dis-select"><span class="name">Recent Update</span></div><div class="widget-body fs14"><a class="item title" href="/2025/01/20/20250220-dynamic-programming-complete-guide/"><span class="title">åŠ¨æ€è§„åˆ’å®Œå…¨æŒ‡å—ï¼šä»å…¥é—¨åˆ°ç²¾é€š</span></a><a class="item title" href="/2019/08/28/20190828-shutil%E6%A8%A1%E5%9D%97/"><span class="title">shutilæ¨¡å—</span></a><a class="item title" href="/2019/09/06/20190906-%E5%8F%98%E6%80%81%E8%B7%B3%E5%8F%B0%E9%98%B6/"><span class="title">å˜æ€è·³å°é˜¶</span></a><a class="item title" href="/2019/10/13/20191013-park%E5%81%9C%E8%BD%A6%E5%9C%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"><span class="title">parkåœè½¦åœºé¡¹ç›®å®æˆ˜</span></a><a class="item title" href="/2026/02/03/bert-comprehensive-guide/"><span class="title">BERT å®Œæ•´è§£æï¼šä»è®ºæ–‡åˆ° KV Cache</span></a><a class="item title" href="/2019/08/28/20190828-opencv%E6%A8%A1%E5%9D%97/"><span class="title">opencvæ¨¡å—</span></a><a class="item title" href="/2019/09/02/20190902-%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"><span class="title">ç”¨ä¸¤ä¸ªæ ˆå®ç°é˜Ÿåˆ—</span></a><a class="item title" href="/2019/09/12/20190912-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/"><span class="title">åè½¬é“¾è¡¨</span></a><a class="item title" href="/2019/09/14/20190914-%E6%A0%91%E7%9A%84%E5%AD%90%E7%BB%93%E6%9E%84/"><span class="title">æ ‘çš„å­ç»“æ„</span></a><a class="item title" href="/2019/10/31/20191031-attention-mechanism-xmind/"><span class="title">attention_mechanism_xmind</span></a></div></widget>
</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/caiusy" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/08a41b181ce68.svg"/></a></div></footer>
</div></aside><div class="l_main" id="main">





<div class="article banner slide-up top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">Home</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">Blog</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">æ·±åº¦å­¦ä¹ </a></div>
<div class="flex-row" id="post-meta"><span class="text created">Posted on: <time datetime="2019-11-25T16:00:00.000Z">2019-11-26</time></span><span class="sep updated"></span><span class="text updated">Updated on: <time datetime="2026-02-20T07:15:58.503Z">2026-02-20</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>GAN</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content slide-up"><h3 id="å¯¹æŠ—ç”Ÿæˆç½‘ç»œ-GAN-Generative-Adversarial-Nets"><a href="#å¯¹æŠ—ç”Ÿæˆç½‘ç»œ-GAN-Generative-Adversarial-Nets" class="headerlink" title="å¯¹æŠ—ç”Ÿæˆç½‘ç»œ GAN(Generative Adversarial Nets)"></a>å¯¹æŠ—ç”Ÿæˆç½‘ç»œ GAN(Generative Adversarial Nets)</h3><p><img src="//caius-lu.github.io/2019/11/26/GAN/images/20191126_GAN_%E5%9B%BE%E7%89%871.png" alt="å›¾ç‰‡1"></p>
<h3 id="Adversarial-Nets-Framework"><a href="#Adversarial-Nets-Framework" class="headerlink" title="Adversarial Nets Framework"></a><strong>Adversarial Nets Framework</strong></h3><p><img src="//caius-lu.github.io/2019/11/26/GAN/images/20191126_GAN_%E5%9B%BE%E7%89%872.png" alt="å›¾ç‰‡2"></p>
<p>ç”Ÿæˆå™¨ä¸åˆ¤åˆ«å™¨çŠ¶æ€ç›¸ç­‰</p>
<h4 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h4><p>å®ƒåšçš„æ˜¯å»æœ€å¤§åŒ– Dçš„åŒºåˆ†åº¦ï¼Œæœ€å°åŒ–Gå’Œrealæ•°æ®é›†çš„æ•°æ®åˆ†å¸ƒ</p>
<p>åˆ¤åˆ«æ¨¡å‹ï¼š</p>
<p>D1 å’Œ D2 ç›¸åŒçš„ï¼Œæ˜¯åˆ¤åˆ«å™¨ï¼ŒGæ˜¯ç”Ÿæˆå™¨</p>
<p>ç”Ÿæˆæ¨¡å‹ï¼š</p>
<p>å…ˆè®­ç»ƒåˆ¤åˆ«å™¨ï¼Œåœ¨è®­ç»ƒç”Ÿæˆå™¨ã€‚</p>
<pre><code>1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45  
46  
47  
48  
49  
50  
51  
52  
53  
54  
55  
56  
57  
58  
59  
60  
61  
62  
63  
64  
65  
66  
67  
68  
69  
70  
71  
72  
73  
74  
75  
76  
77  
78  
79  
80  
81  
82  
83  
84  
85  
86  
87  
88  
89  
90  
91  
92  
93  
94  
95  
96  
97  
98  
99  
100  
101  
102  
103  
104  
105  
106  
107  
108  
109  
110  
111  
112  
113  
114  
115  
116  
117  
118  
119  
120  
121  
122  
123  
124  
125  
126  
127  
128  
129  
130  
131  
132  
133  
134  
135  
136  
137  
138  
139  
140  
141  
142  
143  
144  
145  
146  
147  
148  
149  
150  
151  
152  
153  
154  
155  
156  
157  
158  
159  
160  
161  
162  
163  
164  
165  
166  
167  
168  
169  
170  
171  
172  
173  
174  
175  
176  
177  
178  
179  
180  
181  
182  
183  
184  
185  
186  
187  
188  
189  
190  
191  
192  
193  
194  
195  
196  
197  
198  
199  
200  
201  
202  
203  
204  
205  
206  
207  
208  
209  
210  
211  
212  
213  
214  
215  
216  
217  
218  
219  
220  
221  
222  
223  
224  
225  
226  
227  
228  
229  
230  
</code></pre>
<p>| </p>
<pre><code># -*- coding: utf-8 -*-  
# @Author: Your name  
# @Date:   2019-11-26 09:12:52  
# @Last Modified by:   Your name  
# @Last Modified time: 2019-11-26 09:12:52  
import argparse  
import numpy as np  
from scipy.stats import norm  
import tensorflow as tf  
import matplotlib.pyplot as plt  
from matplotlib import animation  
import seaborn as sns  
  
sns.set(color_codes=True)  
  
seed = 42  
np.random.seed(seed)  
tf.set_random_seed(seed)  
  
  
class DataDistribution(object):  
    def __init__(self):  
        self.mu = 4  
        self.sigma = 0.5  
  
    def sample(self, N):  
        samples = np.random.normal(self.mu, self.sigma, N) # ç”Ÿæˆé«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦éšæœºæ•° å‡å€¼ï¼Œæ ‡å‡†å·®  
        samples.sort()  
        return samples  
  
  
class GeneratorDistribution(object):  
    def __init__(self, range):  
        self.range = range  
  
    def sample(self, N):  
        return np.linspace(-self.range, self.range, N) + \  
            np.random.random(N) * 0.01  # ç”Ÿæˆéšæœºæ•°  
  
# å¯¹çº¿æ€§ç›¸ä¹˜è¿›è¡Œåˆå§‹åŒ–  
def linear(input, output_dim, scope=None, stddev=1.0):  
    norm = tf.random_normal_initializer(stddev=stddev)  
    const = tf.constant_initializer(0.0)  
    with tf.variable_scope(scope or 'linear'): # å®šä¹‰å‘½åç©ºé—´  
        w = tf.get_variable('w', [input.get_shape()[1], output_dim], initializer=norm)  
        b = tf.get_variable('b', [output_dim], initializer=const)  
        return tf.matmul(input, w) + b  
  
# ç”Ÿæˆå™¨  
def generator(input, h_dim):  
    # è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯è®¡ç®—æ¿€æ´»å‡½æ•°softplusï¼Œå³log( exp( features ) + 1)  
    h0 = tf.nn.softplus(linear(input, h_dim, 'g0'))  
    h1 = linear(h0, 1, 'g1')  
    return h1  
  
# åˆ¤åˆ«å™¨  
def discriminator(input, h_dim):  
    h0 = tf.tanh(linear(input, h_dim * 2, 'd0'))  
    h1 = tf.tanh(linear(h0, h_dim * 2, 'd1'))  
    h2 = tf.tanh(linear(h1, h_dim * 2, scope='d2'))  
  
    h3 = tf.sigmoid(linear(h2, 1, scope='d3'))  
    return h3  
  
# ä¼˜åŒ–å™¨  
def optimizer(loss, var_list, initial_learning_rate):  
    decay = 0.95  
    num_decay_steps = 150  
    batch = tf.Variable(0)  
    learning_rate = tf.train.exponential_decay(  
        initial_learning_rate,  
        batch,  
        num_decay_steps,  
        decay,  
        staircase=True  
    )  
    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(  
        loss,  
        global_step=batch,  
        var_list=var_list  
    )  
    return optimizer  
  
  
class GAN(object):  
    def __init__(self, data, gen, num_steps, batch_size, log_every):  
        self.data = data  
        self.gen = gen  
        self.num_steps = num_steps  
        self.batch_size = batch_size  
        self.log_every = log_every  
        self.mlp_hidden_size = 4  
        self.learning_rate = 0.03  
  
        self._create_model()  
  
    def _create_model(self):  
  
        with tf.variable_scope('D_pre'):  
            self.pre_input = tf.placeholder(tf.float32, shape=(self.batch_size, 1))  
            self.pre_labels = tf.placeholder(tf.float32, shape=(self.batch_size, 1))  
            D_pre = discriminator(self.pre_input, self.mlp_hidden_size)  
            self.pre_loss = tf.reduce_mean(tf.square(D_pre - self.pre_labels))  
            self.pre_opt = optimizer(self.pre_loss, None, self.learning_rate)  
  
        # This defines the generator network - it takes samples from a noise  
        # distribution as input, and passes them through an MLP.  
        with tf.variable_scope('Gen'):  
            self.z = tf.placeholder(tf.float32, shape=(self.batch_size, 1))  
            self.G = generator(self.z, self.mlp_hidden_size)  
  
        # The discriminator tries to tell the difference between samples from the  
        # true data distribution (self.x) and the generated samples (self.z).  
        #  
        # Here we create two copies of the discriminator network (that share parameters),  
        # as you cannot use the same network with different inputs in TensorFlow.  
        with tf.variable_scope('Disc') as scope:  
            self.x = tf.placeholder(tf.float32, shape=(self.batch_size, 1))  
            self.D1 = discriminator(self.x, self.mlp_hidden_size)  
            scope.reuse_variables()  
            self.D2 = discriminator(self.G, self.mlp_hidden_size)  
  
        # Define the loss for discriminator and generator networks (see the original  
        # paper for details), and create optimizers for both  
        self.loss_d = tf.reduce_mean(-tf.log(self.D1) - tf.log(1 - self.D2))  
        self.loss_g = tf.reduce_mean(-tf.log(self.D2))  
  
        self.d_pre_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='D_pre')  
        self.d_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Disc')  
        self.g_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Gen')  
  
        self.opt_d = optimizer(self.loss_d, self.d_params, self.learning_rate)  
        self.opt_g = optimizer(self.loss_g, self.g_params, self.learning_rate)  
  
    def train(self):  
        with tf.Session() as session:  
            tf.global_variables_initializer().run()  
  
            # pretraining discriminator  
            num_pretrain_steps = 1000  
            for step in range(num_pretrain_steps):  
                d = (np.random.random(self.batch_size) - 0.5) * 10.0  
                labels = norm.pdf(d, loc=self.data.mu, scale=self.data.sigma) # norm.pdf:æ­£æ€æ¦‚ç‡å¯†åº¦å‡½æ•°  
                pretrain_loss, _ = session.run([self.pre_loss, self.pre_opt], {  
                    self.pre_input: np.reshape(d, (self.batch_size, 1)),  
                    self.pre_labels: np.reshape(labels, (self.batch_size, 1))  
                })  
            self.weightsD = session.run(self.d_pre_params)  
            # copy weights from pre-training over to new D network  
            for i, v in enumerate(self.d_params):  
                session.run(v.assign(self.weightsD[i]))  
  
            for step in range(self.num_steps):  
                # update discriminator  
                x = self.data.sample(self.batch_size)  
                z = self.gen.sample(self.batch_size)  
                loss_d, _ = session.run([self.loss_d, self.opt_d], {  
                    self.x: np.reshape(x, (self.batch_size, 1)),  
                    self.z: np.reshape(z, (self.batch_size, 1))  
                })  
  
                # update generator  
                z = self.gen.sample(self.batch_size)  
                loss_g, _ = session.run([self.loss_g, self.opt_g], {  
                    self.z: np.reshape(z, (self.batch_size, 1))  
                })  
  
                if step % self.log_every == 0:  
                    print('{}: {}\t{}'.format(step, loss_d, loss_g))  
                if step % 100 == 0 or step==0 or step == self.num_steps -1 :  
                    self._plot_distributions(session)  
  
    def _samples(self, session, num_points=10000, num_bins=100):  
        xs = np.linspace(-self.gen.range, self.gen.range, num_points)  
        bins = np.linspace(-self.gen.range, self.gen.range, num_bins)  
  
        # data distribution  
        d = self.data.sample(num_points)  
        pd, _ = np.histogram(d, bins=bins, density=True)  
  
        # generated samples  
        zs = np.linspace(-self.gen.range, self.gen.range, num_points)  
        g = np.zeros((num_points, 1))  
        for i in range(num_points // self.batch_size):  
            g[self.batch_size * i:self.batch_size * (i + 1)] = session.run(self.G, {  
                self.z: np.reshape(  
                    zs[self.batch_size * i:self.batch_size * (i + 1)],  
                    (self.batch_size, 1)  
                )  
            })  
        pg, _ = np.histogram(g, bins=bins, density=True)  
  
        return pd, pg  
  
    def _plot_distributions(self, session):  
        pd, pg = self._samples(session)  
        p_x = np.linspace(-self.gen.range, self.gen.range, len(pd))  
        f, ax = plt.subplots(1)  
        ax.set_ylim(0, 1)  
        plt.plot(p_x, pd, label='real data')  
        plt.plot(p_x, pg, label='generated data')  
        plt.title('1D Generative Adversarial Network')  
        plt.xlabel('Data values')  
        plt.ylabel('Probability density')  
        plt.legend()  
        plt.show()  
def main(args):  
    model = GAN(  
        DataDistribution(),  
        GeneratorDistribution(range=8),  
        args.num_steps,  
        args.batch_size,  
        args.log_every,  
    )  
    model.train()  
  
  
def parse_args():  
    parser = argparse.ArgumentParser()  
    parser.add_argument('--num-steps', type=int, default=12000,  
                        help='the number of training steps to take')  
    parser.add_argument('--batch-size', type=int, default=12,  
                        help='the batch size')  
    parser.add_argument('--log-every', type=int, default=10,  
                        help='print loss after this many steps')  
    return parser.parse_args()  
  
  
if __name__ == '__main__':  
    main(parse_args())  
  
</code></pre>
<p>â€”|â€”  </p>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/images/20191126_GAN_myplot.png" alt="myplot"></p>
<h4 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h4><ol>
<li><p>å°†poolingå±‚convolutionsæ›¿ä»£ </p>
<ul>
<li><p>å¯¹äºåˆ¤åˆ«æ¨¡å‹ï¼šå®¹è®¸ç½‘ç»œå­¦ä¹ è‡ªå·±çš„ç©ºé—´ä¸‹é‡‡æ ·</p>
</li>
<li><p>å¯¹äºç”Ÿæˆæ¨¡å‹ï¼šå®¹è®¸å®ƒå­¦ä¹ è‡ªå·±çš„ç©ºé—´ä¸Šé‡‡æ ·</p>
</li>
</ul>
</li>
<li><p>åœ¨generatorå’Œdiscriminatorä¸Šéƒ½ä½¿ç”¨batchnorm </p>
<ul>
<li>è§£å†³åˆå§‹åŒ–å·®çš„é—®é¢˜</li>
<li>å¸®åŠ©æ¢¯åº¦ä¼ æ’­åˆ°æ¯ä¸€å±‚</li>
<li>é˜²æ­¢generatoræŠŠæ‰€æœ‰çš„æ ·æœ¬éƒ½æ”¶æ•›åˆ°åŒä¸€ä¸ªç‚¹ã€‚</li>
</ul>
</li>
<li><p>åœ¨CNNä¸­ç§»é™¤å…¨è¿æ¥å±‚</p>
</li>
<li><p>åœ¨generatorçš„é™¤äº†è¾“å‡ºå±‚å¤–çš„æ‰€æœ‰å±‚ä½¿ç”¨ReLUï¼Œè¾“å‡ºå±‚é‡‡ç”¨tanhã€‚</p>
</li>
<li><p>åœ¨discriminatorçš„æ‰€æœ‰å±‚ä¸Šä½¿ç”¨LeakyReLU</p>
</li>
</ol>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/images/20191126_GAN_33.png" alt="33"></p>
<p>100ç»´çš„å‘é‡è½¬ä¸ºä¸ºç‰¹å¾å›¾ç›¸ä¼¼çš„ä¸œè¥¿ï¼Œ å†å°†è¿™ä¸ªå‘é‡reshape ã€‚ä½¿ç”¨åå·ç§¯æ“ä½œã€‚</p>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/images/20191126_GAN_a22.png" alt="a22"></p>
<p>è¾“å…¥å›¾ç‰‡ï¼Œå¾—åˆ°ä¸€ä¸ªå€¼æ˜¯0æˆ–è€…1ï¼Œè¿™ä¸ªæ˜¯åˆ¤åˆ«ç½‘ç»œ</p>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/images/20191126_GAN_aa1.png" alt="aa1"></p>
<p>è¿™ä¸ªæ˜¯ç”Ÿæˆç½‘ç»œã€‚<br>model.py  </p>
<pre><code>1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45  
46  
47  
48  
49  
50  
51  
52  
53  
54  
55  
56  
57  
58  
59  
60  
61  
62  
63  
64  
65  
66  
67  
68  
69  
70  
71  
72  
73  
74  
75  
76  
77  
78  
79  
80  
81  
82  
83  
84  
85  
86  
87  
88  
89  
90  
91  
92  
93  
94  
95  
96  
97  
98  
99  
100  
101  
102  
103  
104  
105  
106  
107  
108  
109  
110  
111  
112  
113  
114  
115  
116  
117  
118  
119  
120  
121  
122  
123  
124  
125  
126  
127  
128  
129  
130  
131  
132  
133  
134  
135  
136  
137  
138  
139  
140  
141  
142  
143  
144  
145  
146  
147  
148  
149  
150  
151  
152  
153  
154  
155  
156  
157  
158  
159  
160  
161  
162  
163  
164  
165  
166  
167  
168  
169  
170  
171  
172  
173  
174  
175  
176  
177  
178  
179  
180  
181  
182  
183  
184  
185  
186  
187  
188  
189  
190  
191  
192  
193  
194  
195  
196  
197  
198  
199  
200  
201  
202  
203  
204  
205  
206  
207  
208  
209  
210  
211  
212  
213  
214  
215  
216  
217  
218  
219  
220  
221  
222  
223  
224  
225  
226  
227  
228  
229  
230  
231  
232  
233  
234  
235  
236  
237  
238  
239  
240  
241  
242  
243  
244  
245  
246  
247  
248  
249  
250  
251  
252  
253  
254  
255  
256  
257  
258  
259  
260  
261  
262  
263  
264  
265  
266  
267  
268  
269  
270  
271  
272  
273  
274  
275  
276  
277  
278  
279  
280  
281  
282  
283  
284  
285  
286  
287  
288  
289  
290  
291  
292  
293  
294  
295  
296  
297  
298  
299  
300  
301  
302  
303  
304  
305  
306  
307  
308  
309  
310  
311  
312  
313  
314  
315  
316  
317  
318  
319  
320  
321  
322  
323  
324  
325  
326  
327  
328  
329  
330  
331  
332  
333  
334  
335  
336  
337  
338  
339  
340  
341  
342  
343  
344  
345  
346  
347  
348  
349  
350  
351  
352  
353  
354  
355  
356  
357  
358  
359  
360  
361  
362  
363  
364  
365  
366  
367  
368  
369  
370  
371  
372  
373  
374  
375  
376  
377  
378  
379  
380  
381  
382  
383  
384  
385  
386  
387  
388  
389  
390  
391  
392  
393  
394  
395  
396  
397  
398  
399  
400  
401  
402  
403  
404  
405  
406  
407  
408  
409  
410  
411  
412  
413  
414  
415  
416  
417  
418  
419  
420  
421  
422  
423  
424  
425  
426  
427  
428  
429  
430  
431  
432  
433  
434  
435  
436  
437  
438  
439  
440  
441  
442  
443  
444  
445  
446  
447  
448  
449  
450  
451  
452  
453  
454  
455  
456  
457  
458  
459  
460  
461  
462  
463  
464  
465  
466  
467  
468  
469  
470  
471  
472  
473  
474  
475  
476  
477  
478  
479  
480  
481  
482  
483  
484  
485  
486  
487  
488  
489  
490  
491  
492  
493  
494  
495  
496  
497  
498  
499  
500  
501  
502  
503  
504  
505  
506  
507  
508  
509  
510  
511  
512  
513  
514  
515  
516  
517  
518  
519  
520  
521  
522  
523  
</code></pre>
<p>| </p>
<pre><code>from __future__ import division  
import os  
import time  
import math  
from glob import glob  
import tensorflow as tf  
import numpy as np  
from six.moves import xrange  
  
from ops import *  
from utils import *  
  
def conv_out_size_same(size, stride):  
  return math.ceil(float(size) / float(stride))  
  
class DCGAN(object):  
  def __init__(self, sess, input_height=108, input_width=108, is_crop=True,  
         batch_size=64, sample_num = 64, output_height=64, output_width=64,  
         y_dim=None, z_dim=100, gf_dim=64, df_dim=64,  
         gfc_dim=1024, dfc_dim=1024, c_dim=3, dataset_name='default',  
         input_fname_pattern='*.jpg', checkpoint_dir=None, sample_dir=None):  
    """  
    # sample number  æµ‹è¯•å™ªéŸ³çš„è¾“å‡ºï¼Œyä»£è¡¨label  
    Args:  
      sess: TensorFlow session  
      batch_size: The size of batch. Should be specified before training.  
      y_dim: (optional) Dimension of dim for y. [None]  
      z_dim: (optional) Dimension of dim for Z. [100]  
      gf_dim: (optional) Dimension of gen filters in first conv layer. [64]  
      df_dim: (optional) Dimension of discrim filters in first conv layer. [64]  
      gfc_dim: (optional) Dimension of gen units for for fully connected layer. [1024]  
      dfc_dim: (optional) Dimension of discrim units for fully connected layer. [1024]  
      c_dim: (optional) Dimension of image color. For grayscale input, set to 1. [3]  
    """  
    self.sess = sess  
    self.is_crop = is_crop  
    self.is_grayscale = (c_dim == 1)  
  
    self.batch_size = batch_size  
    self.sample_num = sample_num  
  
    self.input_height = input_height  
    self.input_width = input_width  
    self.output_height = output_height  
    self.output_width = output_width  
  
    self.y_dim = y_dim # null  
    self.z_dim = z_dim # å™ªéŸ³ç‚¹çš„ç»´åº¦ 100  
  
    self.gf_dim = gf_dim # æœ€ç»ˆå¤šå°‘ä¸ªfilterçš„ä¸ªæ•° åŸºæ•°  
    self.df_dim = df_dim # 64  
  
    self.gfc_dim = gfc_dim# ç”Ÿæˆå’Œåˆ¤åˆ«çš„å…¨è¿æ¥ 1024  
    self.dfc_dim = dfc_dim # 1024  
  
    self.c_dim = c_dim# ç”Ÿæˆçš„æ˜¯å½©è‰²å›¾ 3  
  
    # batch normalization : deals with poor initialization helps gradient flow  
    self.d_bn1 = batch_norm(name='d_bn1')# bacthåœ¨reluä¹‹å‰å·ç§¯ä¹‹å  
    self.d_bn2 = batch_norm(name='d_bn2')  
  
    if not self.y_dim:  
      self.d_bn3 = batch_norm(name='d_bn3')  
  
    self.g_bn0 = batch_norm(name='g_bn0')  
    self.g_bn1 = batch_norm(name='g_bn1')  
    self.g_bn2 = batch_norm(name='g_bn2')  
  
    if not self.y_dim:  
      self.g_bn3 = batch_norm(name='g_bn3')  
  
    self.dataset_name = dataset_name  
    self.input_fname_pattern = input_fname_pattern  
    self.checkpoint_dir = checkpoint_dir  
    self.build_model()  
  
  def build_model(self):  
    if self.y_dim:  
      self.y= tf.placeholder(tf.float32, [self.batch_size, self.y_dim], name='y')  
  
    if self.is_crop:  
      image_dims = [self.output_height, self.output_width, self.c_dim]  
    else:  
      image_dims = [self.input_height, self.input_height, self.c_dim]  
  
    self.inputs = tf.placeholder(  
      tf.float32, [self.batch_size] + image_dims, name='real_images')  
    self.sample_inputs = tf.placeholder(  # 64 108 108 3ï¼Œiamge_dim 108 108 3  
      tf.float32, [self.sample_num] + image_dims, name='sample_inputs')  
  
    inputs = self.inputs  # 64 108 108 3  
    sample_inputs = self.sample_inputs  
  
    self.z = tf.placeholder(  
      tf.float32, [None, self.z_dim], name='z')  ## ç”Ÿæˆç½‘ç»œç»„æœ€å¼€å§‹çš„è¾“å…¥ï¼Œfloat32  # Bï¼Œ 100  
    self.z_sum = histogram_summary("z", self.z)  # åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œå½“éœ€è¦æŸ¥çœ‹ä¸€ä¸ªå¼ é‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å€¼çš„åˆ†å¸ƒæƒ…å†µæ—¶ï¼Œå¯é€šè¿‡tf.summary.histogram()å°†å…¶åˆ†å¸ƒæƒ…å†µä»¥ç›´æ–¹å›¾çš„å½¢å¼åœ¨TensorBoardç›´æ–¹å›¾ä»ªè¡¨æ¿ä¸Šæ˜¾ç¤ºï¼  
  
    if self.y_dim:  
      self.G = self.generator(self.z, self.y)  
      self.D, self.D_logits = \  
          self.discriminator(inputs, self.y, reuse=False)  
  
      self.sampler = self.sampler(self.z, self.y)  
      self.D_, self.D_logits_ = \  
          self.discriminator(self.G, self.y, reuse=True)  
    else:  
      self.G = self.generator(self.z)  # 64 64 64 3  
      self.D, self.D_logits = self.discriminator(inputs)  # 64 108 108 3  
  
      self.sampler = self.sampler(self.z)  
      self.D_, self.D_logits_ = self.discriminator(self.G, reuse=True)  
  
    self.d_sum = histogram_summary("d", self.D)  
    self.d__sum = histogram_summary("d_", self.D_)  
    self.G_sum = image_summary("G", self.G)  
    # tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_logits,l)  
    self.d_loss_real = tf.reduce_mean(  
      tf.nn.sigmoid_cross_entropy_with_logits(  
        logits=self.D_logits, labels=tf.ones_like(self.D)))   
    self.d_loss_fake = tf.reduce_mean(  
      tf.nn.sigmoid_cross_entropy_with_logits(  
        logits=self.D_logits_, labels=tf.zeros_like(self.D_)))  
    self.g_loss = tf.reduce_mean(  
      tf.nn.sigmoid_cross_entropy_with_logits(  
        logits=self.D_logits_, labels=tf.ones_like(self.D_)))  
  
    self.d_loss_real_sum = scalar_summary("d_loss_real", self.d_loss_real)  
    self.d_loss_fake_sum = scalar_summary("d_loss_fake", self.d_loss_fake)  
                            
    self.d_loss = self.d_loss_real + self.d_loss_fake  
  
    self.g_loss_sum = scalar_summary("g_loss", self.g_loss)  
    self.d_loss_sum = scalar_summary("d_loss", self.d_loss)  
  
    t_vars = tf.trainable_variables()  
  
    self.d_vars = [var for var in t_vars if 'd_' in var.name]  
    self.g_vars = [var for var in t_vars if 'g_' in var.name]  
  
    self.saver = tf.train.Saver()  
  
  def train(self, config):  
    """Train DCGAN"""  
    if config.dataset == 'mnist':  
      data_X, data_y = self.load_mnist()  
    else:  
      data = glob(os.path.join("./data", config.dataset, self.input_fname_pattern))  
    #np.random.shuffle(data)  
  
    d_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \  
              .minimize(self.d_loss, var_list=self.d_vars)  
    g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \  
              .minimize(self.g_loss, var_list=self.g_vars)  
    try:  
      tf.global_variables_initializer().run()  
    except:  
      tf.initialize_all_variables().run()  
  
    self.g_sum = merge_summary([self.z_sum, self.d__sum,  
      self.G_sum, self.d_loss_fake_sum, self.g_loss_sum])  
    self.d_sum = merge_summary(  
        [self.z_sum, self.d_sum, self.d_loss_real_sum, self.d_loss_sum])  
    self.writer = SummaryWriter("./logs", self.sess.graph)  
  
    sample_z = np.random.uniform(-1, 1, size=(self.sample_num , self.z_dim))  
      
    if config.dataset == 'mnist':  
      sample_inputs = data_X[0:self.sample_num]  
      sample_labels = data_y[0:self.sample_num]  
    else:  
      sample_files = data[0:self.sample_num]  
      sample = [  
          get_image(sample_file,  
                    input_height=self.input_height,  
                    input_width=self.input_width,  
                    resize_height=self.output_height,  
                    resize_width=self.output_width,  
                    is_crop=self.is_crop,  
                    is_grayscale=self.is_grayscale) for sample_file in sample_files]  
      if (self.is_grayscale):  
        sample_inputs = np.array(sample).astype(np.float32)[:, :, :, None]  
      else:  
        sample_inputs = np.array(sample).astype(np.float32)  
    
    counter = 1  
    start_time = time.time()  
  
    if self.load(self.checkpoint_dir):  
      print(" [*] Load SUCCESS")  
    else:  
      print(" [!] Load failed...")  
  
    for epoch in xrange(config.epoch):  
      if config.dataset == 'mnist':  
        batch_idxs = min(len(data_X), config.train_size) // config.batch_size  
      else:        
        data = glob(os.path.join(  
          "./data", config.dataset, self.input_fname_pattern))  
        batch_idxs = min(len(data), config.train_size) // config.batch_size  
  
      for idx in xrange(0, batch_idxs):  
        if config.dataset == 'mnist':  
          batch_images = data_X[idx*config.batch_size:(idx+1)*config.batch_size]  
          batch_labels = data_y[idx*config.batch_size:(idx+1)*config.batch_size]  
        else:  
          batch_files = data[idx*config.batch_size:(idx+1)*config.batch_size]  
          batch = [  
              get_image(batch_file,  
                        input_height=self.input_height,  
                        input_width=self.input_width,  
                        resize_height=self.output_height,  
                        resize_width=self.output_width,  
                        is_crop=self.is_crop,  
                        is_grayscale=self.is_grayscale) for batch_file in batch_files]  
          if (self.is_grayscale):  
            batch_images = np.array(batch).astype(np.float32)[:, :, :, None]  
          else:  
            batch_images = np.array(batch).astype(np.float32)  
        #  ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒ[low,high)ä¸­éšæœºé‡‡æ · ä»+1å’Œ-1ä¹‹é—´éšæ‰é‡‡æ ·  
        batch_z = np.random.uniform(-1, 1, [config.batch_size, self.z_dim]) \  
          .astype(np.float32)  
  
        if config.dataset == 'mnist':  
          # Update D network  
          _, summary_str = self.sess.run([d_optim, self.d_sum],  
            feed_dict={   
              self.inputs: batch_images,  
              self.z: batch_z,  
              self.y:batch_labels,  
            })  
          self.writer.add_summary(summary_str, counter)  
  
          # Update G network  
          _, summary_str = self.sess.run([g_optim, self.g_sum],  
            feed_dict={  
              self.z: batch_z,   
              self.y:batch_labels,  
            })  
          self.writer.add_summary(summary_str, counter)  
  
          # Run g_optim twice to make sure that d_loss does not go to zero (different from paper)  
          _, summary_str = self.sess.run([g_optim, self.g_sum],  
            feed_dict={ self.z: batch_z, self.y:batch_labels })  
          self.writer.add_summary(summary_str, counter)  
            
          errD_fake = self.d_loss_fake.eval({  
              self.z: batch_z,   
              self.y:batch_labels  
          })  
          errD_real = self.d_loss_real.eval({  
              self.inputs: batch_images,  
              self.y:batch_labels  
          })  
          errG = self.g_loss.eval({  
              self.z: batch_z,  
              self.y: batch_labels  
          })  
        else:  
          # Update D network  
          _, summary_str = self.sess.run([d_optim, self.d_sum],  
            feed_dict={ self.inputs: batch_images, self.z: batch_z })  
          self.writer.add_summary(summary_str, counter)  
  
          # Update G network  
          _, summary_str = self.sess.run([g_optim, self.g_sum],  
            feed_dict={ self.z: batch_z })  
          self.writer.add_summary(summary_str, counter)  
  
          # Run g_optim twice to make sure that d_loss does not go to zero (different from paper)  
          _, summary_str = self.sess.run([g_optim, self.g_sum],  
            feed_dict={ self.z: batch_z })  
          self.writer.add_summary(summary_str, counter)  
            
          errD_fake = self.d_loss_fake.eval({ self.z: batch_z })  
          errD_real = self.d_loss_real.eval({ self.inputs: batch_images })  
          errG = self.g_loss.eval({self.z: batch_z})  
  
        counter += 1  
        print("Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f" \  
          % (epoch, idx, batch_idxs,  
            time.time() - start_time, errD_fake+errD_real, errG))  
  
        if np.mod(counter, 100) == 1:  
          if config.dataset == 'mnist':  
            samples, d_loss, g_loss = self.sess.run(  
              [self.sampler, self.d_loss, self.g_loss],  
              feed_dict={  
                  self.z: sample_z,  
                  self.inputs: sample_inputs,  
                  self.y:sample_labels,  
              }  
            )  
            save_images(samples, [8, 8],  
                  './{}/train_{:02d}_{:04d}.png'.format(config.sample_dir, epoch, idx))  
            print("[Sample] d_loss: %.8f, g_loss: %.8f" % (d_loss, g_loss))   
          else:  
            try:  
              samples, d_loss, g_loss = self.sess.run(  
                [self.sampler, self.d_loss, self.g_loss],  
                feed_dict={  
                    self.z: sample_z,  
                    self.inputs: sample_inputs,  
                },  
              )  
              save_images(samples, [8, 8],  
                    './{}/train_{:02d}_{:04d}.png'.format(config.sample_dir, epoch, idx))  
              print("[Sample] d_loss: %.8f, g_loss: %.8f" % (d_loss, g_loss))   
            except:  
              print("one pic error!...")  
  
        if counter//10 == 2:  
          self.save(config.checkpoint_dir, counter)  
  
  def discriminator(self, image, y=None, reuse=False):  
    with tf.variable_scope("discriminator") as scope:  
      if reuse:  
        scope.reuse_variables()  
  
      if not self.y_dim:  
        h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))  
        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv')))  
        h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*4, name='d_h2_conv')))  
        h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*8, name='d_h3_conv'))) # 64 14 14 256 -&gt;64 7 7 512  
        aa = tf.reshape(h3, [self.batch_size, -1])  
        h4 = linear(aa, 1, 'd_h3_lin')  
  
        return tf.nn.sigmoid(h4), h4  
      else:  
        yb = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])  
        x = conv_cond_concat(image, yb)  
  
        h0 = lrelu(conv2d(x, self.c_dim + self.y_dim, name='d_h0_conv'))  
        h0 = conv_cond_concat(h0, yb)  
  
        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim + self.y_dim, name='d_h1_conv')))  
        h1 = tf.reshape(h1, [self.batch_size, -1])        
        h1 = concat([h1, y], 1)  
          
        h2 = lrelu(self.d_bn2(linear(h1, self.dfc_dim, 'd_h2_lin')))  
        h2 = concat([h2, y], 1)  
  
        h3 = linear(h2, 1, 'd_h3_lin')  
          
        return tf.nn.sigmoid(h3), h3  
  
  def generator(self, z, y=None):  
    with tf.variable_scope("generator") as scope:  
      if not self.y_dim:  
        s_h, s_w = self.output_height, self.output_width  
        s_h2, s_w2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2) # å…ˆæŠŠç‰¹å¾å›¾å¤§å°ç¡®å®šå‡ºæ¥  
        s_h4, s_w4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2)  
        s_h8, s_w8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2)  
        s_h16, s_w16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2)  
  
        # project `z` and reshape  
        self.z_, self.h0_w, self.h0_b = linear(  
            z, self.gf_dim*8*s_h16*s_w16, 'g_h0_lin', with_w=True)  
  
        self.h0 = tf.reshape(  
            self.z_, [-1, s_h16, s_w16, self.gf_dim * 8])  
        h0 = tf.nn.relu(self.g_bn0(self.h0))  
  
        self.h1, self.h1_w, self.h1_b = deconv2d(  
            h0, [self.batch_size, s_h8, s_w8, self.gf_dim*4], name='g_h1', with_w=True)  
        h1 = tf.nn.relu(self.g_bn1(self.h1))  
  
        h2, self.h2_w, self.h2_b = deconv2d(  
            h1, [self.batch_size, s_h4, s_w4, self.gf_dim*2], name='g_h2', with_w=True)  
        h2 = tf.nn.relu(self.g_bn2(h2))  
  
        h3, self.h3_w, self.h3_b = deconv2d(  
            h2, [self.batch_size, s_h2, s_w2, self.gf_dim*1], name='g_h3', with_w=True)  
        h3 = tf.nn.relu(self.g_bn3(h3))  
  
        h4, self.h4_w, self.h4_b = deconv2d(  
            h3, [self.batch_size, s_h, s_w, self.c_dim], name='g_h4', with_w=True)  
  
        return tf.nn.tanh(h4)  
      else:  
        s_h, s_w = self.output_height, self.output_width  
        s_h2, s_h4 = int(s_h/2), int(s_h/4)  
        s_w2, s_w4 = int(s_w/2), int(s_w/4)  
  
        # yb = tf.expand_dims(tf.expand_dims(y, 1),2)  
        yb = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])  
        z = concat([z, y], 1)  
  
        h0 = tf.nn.relu(  
            self.g_bn0(linear(z, self.gfc_dim, 'g_h0_lin')))  
        h0 = concat([h0, y], 1)  
  
        h1 = tf.nn.relu(self.g_bn1(  
            linear(h0, self.gf_dim*2*s_h4*s_w4, 'g_h1_lin')))  
        h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * 2])  
  
        h1 = conv_cond_concat(h1, yb)  
  
        h2 = tf.nn.relu(self.g_bn2(deconv2d(h1,  
            [self.batch_size, s_h2, s_w2, self.gf_dim * 2], name='g_h2')))  
        h2 = conv_cond_concat(h2, yb)  
  
        return tf.nn.sigmoid(  
            deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name='g_h3'))  
  
  def sampler(self, z, y=None):  
    with tf.variable_scope("generator") as scope:  
      scope.reuse_variables()  
  
      if not self.y_dim:  
        s_h, s_w = self.output_height, self.output_width  
        s_h2, s_w2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2)  
        s_h4, s_w4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2)  
        s_h8, s_w8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2)  
        s_h16, s_w16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2)  
  
        # project `z` and reshape  
        h0 = tf.reshape(  
            linear(z, self.gf_dim*8*s_h16*s_w16, 'g_h0_lin'),  
            [-1, s_h16, s_w16, self.gf_dim * 8])  
        h0 = tf.nn.relu(self.g_bn0(h0, train=False))  
  
        h1 = deconv2d(h0, [self.batch_size, s_h8, s_w8, self.gf_dim*4], name='g_h1')  
        h1 = tf.nn.relu(self.g_bn1(h1, train=False))  
  
        h2 = deconv2d(h1, [self.batch_size, s_h4, s_w4, self.gf_dim*2], name='g_h2')  
        h2 = tf.nn.relu(self.g_bn2(h2, train=False))  
  
        h3 = deconv2d(h2, [self.batch_size, s_h2, s_w2, self.gf_dim*1], name='g_h3')  
        h3 = tf.nn.relu(self.g_bn3(h3, train=False))  
  
        h4 = deconv2d(h3, [self.batch_size, s_h, s_w, self.c_dim], name='g_h4')  
  
        return tf.nn.tanh(h4)  
      else:  
        s_h, s_w = self.output_height, self.output_width  
        s_h2, s_h4 = int(s_h/2), int(s_h/4)  
        s_w2, s_w4 = int(s_w/2), int(s_w/4)  
  
        # yb = tf.reshape(y, [-1, 1, 1, self.y_dim])  
        yb = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])  
        z = concat([z, y], 1)  
  
        h0 = tf.nn.relu(self.g_bn0(linear(z, self.gfc_dim, 'g_h0_lin')))  
        h0 = concat([h0, y], 1)  
  
        h1 = tf.nn.relu(self.g_bn1(  
            linear(h0, self.gf_dim*2*s_h4*s_w4, 'g_h1_lin'), train=False))  
        h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * 2])  
        h1 = conv_cond_concat(h1, yb)  
  
        h2 = tf.nn.relu(self.g_bn2(  
            deconv2d(h1, [self.batch_size, s_h2, s_w2, self.gf_dim * 2], name='g_h2'), train=False))  
        h2 = conv_cond_concat(h2, yb)  
  
        return tf.nn.sigmoid(deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name='g_h3'))  
  
  def load_mnist(self):  
    data_dir = os.path.join("./data", self.dataset_name)  
      
    fd = open(os.path.join(data_dir,'train-images-idx3-ubyte'))  
    loaded = np.fromfile(file=fd,dtype=np.uint8)  
    trX = loaded[16:].reshape((60000,28,28,1)).astype(np.float)  
  
    fd = open(os.path.join(data_dir,'train-labels-idx1-ubyte'))  
    loaded = np.fromfile(file=fd,dtype=np.uint8)  
    trY = loaded[8:].reshape((60000)).astype(np.float)  
  
    fd = open(os.path.join(data_dir,'t10k-images-idx3-ubyte'))  
    loaded = np.fromfile(file=fd,dtype=np.uint8)  
    teX = loaded[16:].reshape((10000,28,28,1)).astype(np.float)  
  
    fd = open(os.path.join(data_dir,'t10k-labels-idx1-ubyte'))  
    loaded = np.fromfile(file=fd,dtype=np.uint8)  
    teY = loaded[8:].reshape((10000)).astype(np.float)  
  
    trY = np.asarray(trY)  
    teY = np.asarray(teY)  
      
    X = np.concatenate((trX, teX), axis=0)  
    y = np.concatenate((trY, teY), axis=0).astype(np.int)  
      
    seed = 547  
    np.random.seed(seed)  
    np.random.shuffle(X)  
    np.random.seed(seed)  
    np.random.shuffle(y)  
      
    y_vec = np.zeros((len(y), self.y_dim), dtype=np.float)  
    for i, label in enumerate(y):  
      y_vec[i,y[i]] = 1.0  
      
    return X/255.,y_vec  
  
  @property  
  def model_dir(self):  
    return "{}_{}_{}_{}".format(  
        self.dataset_name, self.batch_size,  
        self.output_height, self.output_width)  
        
  def save(self, checkpoint_dir, step):  
    model_name = "DCGAN.model"  
    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)  
  
    if not os.path.exists(checkpoint_dir):  
      os.makedirs(checkpoint_dir)  
  
    self.saver.save(self.sess,  
            os.path.join(checkpoint_dir, model_name),  
            global_step=step)  
  
  def load(self, checkpoint_dir):  
    print(" [*] Reading checkpoints...")  
    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)  
  
    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)  
    if ckpt and ckpt.model_checkpoint_path:  
      ckpt_name = os.path.basename(ckpt.model_checkpoint_path)  
      self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))  
      print(" [*] Success to read {}".format(ckpt_name))  
      return True  
    else:  
      print(" [*] Failed to find a checkpoint")  
      return False  
  
</code></pre>
<p>â€”|â€”</p>
</article>
<div class="article-footer slide-up">


    <section id="share">
      <div class="header"><span>Share</span></div>
      <div class="body">
        <div class="link"><input class="copy-area" readonly="true" id="copy-link" value="https://caiusy.github.io/2019/11/26/GAN/" /></div>
        <div class="social-wrap dis-select"><a class="social share-item wechat" onclick="util.toggle(&quot;qrcode-wechat&quot;)"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/b32ef3da1162a.svg" /></a><a class="social share-item link" onclick="util.copy(&quot;copy-link&quot;, &quot;Copied!&quot;)"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/8411ed322ced6.svg" /></a></div>
        
        <div class="qrcode" id="qrcode-wechat" style="opacity:0;height:0">
          <img src="https://api.qrserver.com/v1/create-qr-code/?size=256x256&data=https://caiusy.github.io/2019/11/26/GAN/"/>
        </div>
        
      </div>
    </section>
    </div>

<div class="related-wrap slide-up" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">Newer</div><a href="/2019/11/26/20191126-GAN/">GAN</a></div><div class="item" id="next"><div class="note">Older</div><a href="/2019/11/17/20191117-DFS-BFS/">DFS_BFS</a></div></section></div>




  <div class="related-wrap md-text slide-up" id="comments">
    <section class='header cmt-title cap theme'>
      <p>ğŸ’¬ æ¬¢è¿ç•™è¨€è®¨è®º</p>

    </section>
    <section class='body cmt-body giscus'>
      

<svg class="loading" style="vertical-align:middle;fill:currentColor;overflow:hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="giscus" src="https://giscus.app/client.js" data-repo="caiusy/caiusy.github.io" data-repo-id="R_kgDOI0diCA" data-category="Announcements" data-category-id="DIC_kwDOI0diCM4C1G8d" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous"></div>

    </section>
  </div>



<footer class="page-footer slide-up footnote"><hr><div class="sitemap" style="column-count:3;"><div class="sitemap-group"><span class="fs15">åšå®¢</span><a href="/">è¿‘æœŸå‘å¸ƒ</a><a href="/categories/">åˆ†ç±»</a><a href="/tags/">æ ‡ç­¾</a><a href="/archives/">å½’æ¡£</a></div><div class="sitemap-group"><span class="fs15">æŠ€æœ¯é¢†åŸŸ</span><a href="/tags/CV/">è®¡ç®—æœºè§†è§‰</a><a href="/tags/tracking/">ç›®æ ‡è·Ÿè¸ª</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">æ·±åº¦å­¦ä¹ </a></div><div class="sitemap-group"><span class="fs15">å…³äº</span><a href="/about/">å…³äºæˆ‘</a><a target="_blank" rel="noopener" href="https://github.com/caiusy">GitHub</a></div></div><div class="text"><p>æœ¬ç«™ç”± <strong>Caius Lu</strong> ä½¿ç”¨ <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> ä¸»é¢˜åˆ›å»º<br>Â© 2023-2026 Â· æ¢ç´¢ AI ä¸è®¡ç®—æœºè§†è§‰çš„æ— é™å¯èƒ½ ğŸš€</p>
<p><span id="busuanzi_container_site_pv">æœ¬ç«™æ€»è®¿é—®é‡ <span id="busuanzi_value_site_pv"></span> æ¬¡</span> | <span id="busuanzi_container_site_uv">è®¿å®¢æ•° <span id="busuanzi_value_site_uv"></span> äºº</span></p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper slide-up toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">On This Page</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C-GAN-Generative-Adversarial-Nets"><span class="toc-text">å¯¹æŠ—ç”Ÿæˆç½‘ç»œ GAN(Generative Adversarial Nets)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adversarial-Nets-Framework"><span class="toc-text">Adversarial Nets Framework</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">æŸå¤±å‡½æ•°</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DCGAN"><span class="toc-text">DCGAN</span></a></li></ol></li></ol></div><div class="widget-footer"><a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5"><path stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/><path d="M7 3.338A9.95 9.95 0 0 1 12 2c5.523 0 10 4.477 10 10s-4.477 10-10 10S2 17.523 2 12c0-1.821.487-3.53 1.338-5"/></g></svg><span>Scroll to Top</span></a><a class="buttom" onclick="util.scrollComment()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M8 10.5h8M8 14h5.5M17 3.338A9.95 9.95 0 0 0 12 2C6.477 2 2 6.477 2 12c0 1.6.376 3.112 1.043 4.453c.178.356.237.763.134 1.148l-.595 2.226a1.3 1.3 0 0 0 1.591 1.592l2.226-.596a1.63 1.63 0 0 1 1.149.133A9.96 9.96 0 0 0 12 22c5.523 0 10-4.477 10-10c0-1.821-.487-3.53-1.338-5"/></svg><span>Join Discussion</span></a></div></widget>
</div></aside><div class='float-panel'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">


<script type="text/javascript">
  window.canonical = {"closeEnable":true,"closeText":"å…³é—­æç¤º","originalHost":null,"officialHosts":["localhost"],"encoded":""};
  window.canonical["param"] = {"permalink":"https://caiusy.github.io/2019/11/26/GAN/","checklink":"/js/plugins/video.js"};
  const ctx = {
    date_suffix: {
      just: `Just`,
      min: `minutes ago`,
      hour: `hours ago`,
      day: `days ago`,
    },
    root : `/`,
    tag_plugins: {
      chat: Object.assign({"api":"https://siteinfo.listentothewind.cn/api/v1"}),
    }
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"skip_search":null,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
    loading: `https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd`,
  };
  const deps = {
    jquery: `https://gcore.jsdelivr.net/npm/jquery@3.7/dist/jquery.min.js`,
    marked: `https://gcore.jsdelivr.net/npm/marked@13.0/lib/marked.umd.min.js`,
    lazyload: `/%5Bobject%20Object%5D`
  }
  

</script>

<script type="text/javascript">
  
  function RunItem() {
    this.list = []; // å­˜æ”¾å›è°ƒå‡½æ•°
    this.start = () => {
      for (var i = 0; i < this.list.length; i++) {
        this.list[i].run();
      }
    };
    this.push = (fn, name, setRequestAnimationFrame = true) => {
      let myfn = fn
      if (setRequestAnimationFrame) {
        myfn = () => {
          utils.requestAnimationFrame(fn)
        }
      }
      var f = new Item(myfn, name);
      this.list.push(f);
    };
    this.remove = (name) => {
      for (let index = 0; index < this.list.length; index++) {
        const e = this.list[index];
        if (e.name == name) {
          this.list.splice(index, 1);
        }
      }
    }
    // æ„é€ ä¸€ä¸ªå¯ä»¥runçš„å¯¹è±¡
    function Item(fn, name) {
      // å‡½æ•°åç§°
      this.name = name || fn.name;
      // runæ–¹æ³•
      this.run = () => {
        try {
          fn()
        } catch (error) {
          console.log(error);
        }
      };
    }
  }

  const utils = {
    // æ‡’åŠ è½½ css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')) {
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // é»˜è®¤å¼‚æ­¥ï¼Œå¦‚æœéœ€è¦åŒæ­¥ï¼Œç¬¬äºŒä¸ªå‚æ•°ä¼ å…¥ {} å³å¯
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function () {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },

    onLoading: (el) => {
      if (el) {
        if ($(el).find('.loading-wrap').length == 0){
          $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
        }
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      const maxRetry = 3;
      let retryCount = 0;

      return new Promise((resolve, reject) => {
        const load = () => {
          utils.onLoading?.(el);

          let timedOut = false;
          const timeout = setTimeout(() => {
            timedOut = true;
            console.warn('[request] è¶…æ—¶:', url);

            if (++retryCount >= maxRetry) {
              utils.onLoadFailure?.(el);
              onFailure?.();
              reject('è¯·æ±‚è¶…æ—¶');
            } else {
              setTimeout(load, 1000);
            }
          }, 5000);

          fetch(url).then(resp => {
            if (timedOut) return;
            clearTimeout(timeout);

            if (!resp.ok) throw new Error('å“åº”å¤±è´¥');
            return resp;
          }).then(data => {
            if (timedOut) return;
            utils.onLoadSuccess?.(el);
            callback(data);
            resolve(data);
          }).catch(err => {
            clearTimeout(timeout);
            console.warn('[request] é”™è¯¯:', err);

            if (++retryCount >= maxRetry) {
              utils.onLoadFailure?.(el);
              onFailure?.();
              reject(err);
            } else {
              setTimeout(load, 1000);
            }
          });
        };

        load();
      });
    },
    requestWithoutLoading: (url, options = {}, maxRetry = 2, timeout = 5000) => {
      return new Promise((resolve, reject) => {
        let retryCount = 0;

        const tryRequest = () => {
          let timedOut = false;
          const timer = setTimeout(() => {
            timedOut = true;
            if (++retryCount > maxRetry) reject('timeout');
            else tryRequest();
          }, timeout);

          fetch(url, options)
            .then(resp => {
              clearTimeout(timer);
              if (!resp.ok) throw new Error('bad response');
              resolve(resp);
            })
            .catch(err => {
              clearTimeout(timer);
              if (++retryCount > maxRetry) reject(err);
              else setTimeout(tryRequest, 500);
            });
        };

        tryRequest();
      });
    },
    /********************** requestAnimationFrame ********************************/
    // 1ã€requestAnimationFrame ä¼šæŠŠæ¯ä¸€å¸§ä¸­çš„æ‰€æœ‰ DOM æ“ä½œé›†ä¸­èµ·æ¥ï¼Œåœ¨ä¸€æ¬¡é‡ç»˜æˆ–å›æµä¸­å°±å®Œæˆï¼Œå¹¶ä¸”é‡ç»˜æˆ–å›æµçš„æ—¶é—´é—´éš”ç´§ç´§è·Ÿéšæµè§ˆå™¨çš„åˆ·æ–°é¢‘ç‡ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªé¢‘ç‡ä¸ºæ¯ç§’60å¸§ã€‚
    // 2ã€åœ¨éšè—æˆ–ä¸å¯è§çš„å…ƒç´ ä¸­ï¼ŒrequestAnimationFrame å°†ä¸ä¼šè¿›è¡Œé‡ç»˜æˆ–å›æµï¼Œè¿™å½“ç„¶å°±æ„å‘³ç€æ›´å°‘çš„çš„ cpuï¼Œgpu å’Œå†…å­˜ä½¿ç”¨é‡ã€‚
    requestAnimationFrame: (fn) => {
      if (!window.requestAnimationFrame) {
        window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame;
      }
      window.requestAnimationFrame(fn)
    },
    dark: {},
  };

  // utils.dark.mode å½“å‰æ¨¡å¼ dark or light
  // utils.dark.toggle() æš—é»‘æ¨¡å¼è§¦å‘å™¨
  // utils.dark.push(callBack[,"callBackName"]) ä¼ å…¥è§¦å‘å™¨å›è°ƒå‡½æ•°
  utils.dark.method = {
    toggle: new RunItem(),
  };
  utils.dark = Object.assign(utils.dark, {
    push: utils.dark.method.toggle.push,
  });
</script>
<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>
<script type="text/javascript">
  (() => {
    const tagSwitchers = document.querySelectorAll('.tag-subtree.parent-tag > a > .tag-switcher-wrapper')
    for (const tagSwitcher of tagSwitchers) {
      tagSwitcher.addEventListener('click', (e) => {
        const parent = e.target.closest('.tag-subtree.parent-tag')
        parent.classList.toggle('expanded')
        e.preventDefault()
      })
    }

    // Get active tag from query string, then activate it.
    const urlParams = new URLSearchParams(window.location.search)
    const activeTag = urlParams.get('tag')
    if (activeTag) {
      let tag = document.querySelector(`.tag-subtree[data-tag="${activeTag}"]`)
      if (tag) {
        tag.querySelector('a').classList.add('active')
        
        while (tag) {
          tag.classList.add('expanded')
          tag = tag.parentElement.closest('.tag-subtree.parent-tag')
        }
      }
    }
  })()
</script>

<script async src="https://gcore.jsdelivr.net/npm/vanilla-lazyload@19.1/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
    callback_loaded: (el) => {
      el.classList.add('loaded');
      const wrapper = el.closest('.lazy-box');
      const icon = wrapper?.querySelector('.lazy-icon');
      if (icon) icon.remove();
    }
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });

  window.wrapLazyloadImages = (container) => {
    if (typeof container === 'string') {
      container = document.querySelector(container);
    }
    if (!container) return;
    
    const images = container.querySelectorAll('img');
    images.forEach((img) => {
      if (img.classList.contains('lazy')) return;

      const src = img.getAttribute('src');
      if (!src) return;

      const wrapper = document.createElement('div');
      wrapper.className = 'lazy-box';

      const newImg = img.cloneNode();
      newImg.removeAttribute('src');
      newImg.setAttribute('data-src', src);
      newImg.classList.add('lazy');

      const icon = document.createElement('div');
      icon.className = 'lazy-icon';
      if (def.loading) {
        icon.style.backgroundImage = `url("${def.loading}")`;
      }

      wrapper.appendChild(newImg);
      wrapper.appendChild(icon);

      img.replaceWith(wrapper);
    });

    // é€šçŸ¥ LazyLoad æ›´æ–°
    if (window.lazyLoadInstance?.update) {
      window.lazyLoadInstance.update();
    }
  }
  
</script>

<!-- required -->
<script src="/js/main.js?v=1.33.1" defer></script>

<script type="text/javascript">
  const applyTheme = (theme) => {
    if (theme === 'auto') {
      document.documentElement.removeAttribute('data-theme')
    } else {
      document.documentElement.setAttribute('data-theme', theme)
    }

    // applyThemeToGiscus(theme)
  }

  // FIXME: è¿™ä¼šå¯¼è‡´æ— æ³•ä½¿ç”¨ preferred_color_scheme ä»¥å¤–çš„ä¸»é¢˜
  const applyThemeToGiscus = (theme) => {
    // theme = theme === 'auto' ? 'preferred_color_scheme' : theme
    const cmt = document.getElementById('giscus')
    if (cmt) {
      // This works before giscus load.
      cmt.setAttribute('data-theme', theme)
    }

    const iframe = document.querySelector('#comments > section.giscus > iframe')
    if (iframe) {
      // This works after giscus loaded.
      const src = iframe.src
      const newSrc = src.replace(/theme=[\w]+/, `theme=${theme}`)
      iframe.src = newSrc
    }
  }

  const switchTheme = () => {
    // light -> dark -> auto -> light -> ...
    const currentTheme = document.documentElement.getAttribute('data-theme')
    let newTheme;
    switch (currentTheme) {
      case 'light':
        newTheme = 'dark'
        break
      case 'dark':
        newTheme = 'auto'
        break
      default:
        newTheme = 'light'
    }
    applyTheme(newTheme)
    window.localStorage.setItem('Stellar.theme', newTheme)
    utils.dark.mode = newTheme === 'auto' ? (window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light") : newTheme;
    utils.dark.method.toggle.start();

    const messages = {
      light: `Switched to Light Mode`,
      dark: `Switched to Dark Mode`,
      auto: `Switched to Auto Mode`,
    }
    hud?.toast?.(messages[newTheme])
  }

  (() => {
    // Apply user's preferred theme, if any.
    const theme = window.localStorage.getItem('Stellar.theme')
    if (theme !== null) {
      applyTheme(theme)
    } else {
      utils.dark.mode = window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
    }
    utils.dark.method.toggle.start();
  })()
</script>


<!-- optional -->

  <script type="module">
  const el = document.querySelector('#comments #giscus');
  util.viewportLazyload(el, load_discus, true);

  function load_discus() {
    if (!el) return;
    try {
        el.innerHTML = '';
      } catch (error) {
        console.error(error);
      }
      const script = document.createElement('script');
      script.async = true;
      for (const key of Object.keys(el.attributes)) {
        const attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
  }
</script>




<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"rating":{"js":"/js/services/rating.js","api":"https://star-vote.xaox.cc/api/rating"},"vote":{"js":"/js/services/vote.js","api":"https://star-vote.xaox.cc/api/vote"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"friends_and_posts":{"js":"/js/services/friends_and_posts.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"},"voice":{"js":"/js/plugins/voice.js"},"video":{"js":"/js/plugins/video.js"},"download-file":{"js":"/js/plugins/download-file.js"},"twikoo":{"js":"/js/services/twikoo_latest_comment.js"},"waline":{"js":"/js/services/waline_latest_comment.js"},"artalk":{"js":"/js/services/artalk_latest_comment.js"},"giscus":{"js":"/js/services/giscus_latest_comment.js"},"contributors":{"edit_this_page":{"_posts/":null,"wiki/stellar/":"https://github.com/xaoxuu/hexo-theme-stellar-docs/blob/main/"},"js":"/js/services/contributors.js"},"rss":{"js":"/js/services/rss.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else if (id == 'voice') {
        ctx.voiceAudios = document.querySelectorAll('.voice>audio');
        if (ctx.voiceAudios?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            createVoiceDom(ctx.voiceAudios);
          });
        }
      } else if (id == 'video') {
        ctx.videos = document.querySelectorAll('.video>video');
        if (ctx.videos?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            videoEvents(ctx.videos);
          });
        }
      } else if (id == 'download-file') {
        ctx.files = document.querySelectorAll('.chat-file');
        if (ctx.files?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            downloadFileEvent(ctx.files);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }

    // chat iphone time
    let phoneTimes = document.querySelectorAll('.chat .status-bar .time');

    if (phoneTimes.length > 0) {
      NowTime();
      var date = new Date();
      var sec = date.getSeconds();
      var firstAdjustInterval = setInterval(firstAdjustTime, 1000 * (60 - sec));
    }

    function firstAdjustTime() {
      NowTime();
      clearInterval(firstAdjustInterval);
      setInterval(NowTime, 1000 * 60);
    }

    function NowTime() {
      for (let i = 0; i < phoneTimes.length; ++i) {
        var timeSpan = phoneTimes[i];
        var date = new Date();
        var hour = date.getHours();
        var min = date.getMinutes();
        timeSpan.innerHTML = check(hour) + ":" + check(min);
      }
    };

    function check(val) {
      if (val < 10) {
        return ("0" + val);
      }
      return (val);
    }

    // chat quote
    const chat_quote_obverser = new IntersectionObserver((entries, observer) => {
      entries.filter((entry) => { return entry.isIntersecting }).sort((a, b) => a.intersectionRect.y !== b.intersectionRect.y ? a.intersectionRect.y - b.intersectionRect.y : a.intersectionRect.x - b.intersectionRect.x).forEach((entry, index) => {
          observer.unobserve(entry.target);
          setTimeout(() => {
            entry.target.classList.add('quote-blink');
            setTimeout(() => {
              entry.target.classList.remove('quote-blink');
            }, 1000);
          }, Math.max(100, 16) * (index + 1));
        });
    });

    var chatQuotes = document.querySelectorAll(".chat .talk .quote");
    chatQuotes.forEach((quote) => {
      quote.addEventListener('click', function () {
        var chatCellDom = document.getElementById("quote-" + quote.getAttribute("quotedCellTag"));
        if (chatCellDom) {
          var chatDiv = chatCellDom.parentElement;
          var mid = chatDiv.clientHeight / 2;
          var offsetTop = chatCellDom.offsetTop;
          if (offsetTop > mid - chatCellDom.clientHeight / 2) {
            chatDiv.scrollTo({
              top: chatCellDom.offsetTop - mid + chatCellDom.clientHeight / 2,
              behavior: "smooth"
            });
          } else {
            chatDiv.scrollTo({
              top: 0,
              behavior: "smooth"
            });
          }
          chat_quote_obverser.observe(chatCellDom);
        }
      });
    });
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://gcore.jsdelivr.net/npm/flying-pages@2/flying-pages.min.js"></script><script>
  ctx.fancybox = {
    selector: `.md-text img:not([class]), .md-text .image img, .timenode p>img`,
    css: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.css`,
    js: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.umd.js`
  };
  var selector = '[data-fancybox]:not(.error), .with-fancybox .atk-content img:not([atk-emoticon])';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const memos = document.getElementsByClassName('ds-memos');
    if (memos != undefined && memos.length > 0) {
      needFancybox = true;
    }
    const fancybox = document.getElementsByClassName('with-fancybox');
    if (fancybox != undefined && fancybox.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || slide.triggerEl.dataset.caption || null
        }
      });
    })
  }
</script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          rewind: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script>
<script defer src="https://gcore.jsdelivr.net/npm/scrollreveal@4.0/dist/scrollreveal.min.js"></script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const slideUp = {
      distance: `16px`,
      duration: `600`,
      interval: `100`,
      scale: `1`,
      opacity: 0,
      easing: "ease-out"
    };
    ScrollReveal().reveal('.slide-up', { ...slideUp });
  });
</script>

<script>
  window.MathJax = {
    tex: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"],
      ],
      processEscapes: true,
      skipTags: ["script", "noscript", "style", "textarea", "pre", "code"],
    },
    startup: {
      ready() {
        MathJax.startup.defaultReady();
        MathJax.typesetPromise().then(() => {
          const math = document.querySelectorAll("mjx-container");
          math.forEach((element) => {
            if (element.parentNode) {
              element.parentNode.classList.add("has-jax");
            }
          });
        });
      },
    },
  };
</script>

<script id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js" async></script>

<script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `å¤åˆ¶æˆåŠŸ`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
