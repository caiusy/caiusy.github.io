---
title: 在手术室多相机多行人跟踪和重识别
categories: 技术
typora-copy-images-to: 在手术室多相机多行人跟踪和重识别
date: 2023-01-24 21:28:12
tags: 技术
---

### 在手术室多相机多行人跟踪和重识别

> Multi-Camera Multi-Person T racking and Re-Identification in
> an Operating Room

#### 摘要

多摄像头多人(MCMP)跟踪与重识别(ReID)是安全、行人分析等方面的重要任务;然而，大多数研究都集中在室外场景，因为在一个有障碍物的拥挤房间里，处理遮挡和错误识别要复杂得多。此外，在一个框架内完成这两项任务具有挑战性。本文提出了一种基于轨迹的方法，将跟踪和ReID任务集成在一起。首先，每台摄像机捕捉到的所有手术成员的姿势被逐帧检测;然后，利用检测到的姿态来跟踪每个摄像机的所有成员的轨迹;最后，将这些不同摄像机的轨迹聚类，通过所有摄像机重新识别手术室中的成员。与其他MCMP跟踪和ReID方法相比，本文提出的方法主要利用轨迹，将手术室场景中不易识别的纹理特征作为辅助线索。本文还在ReID过程中集成了时间信息，这比当前最先进的框架(逐帧进行ReID)更可靠。此外，我们的框架在部署到新场景之前不需要培训。本文还创建了一个带有实际手术室视频的注释MCMP数据集。实验证明了所提出的基于轨迹的ReID算法的有效性。提出的框架在ReID任务中达到了85.44%的准确率，在本文提出的手术室数据集中优于最先进的框架。

#### 介绍

在本文中，我们旨在建立一种在手术室内获得可靠的单目人员跟踪和相机间人员ReID结果的方法。与直接用神经网络提取图像特征相比，我们主要通过运动轨迹进行判断，以纹理特征作为辅助线索。因为工作人员的运动遵循一定的规则，他们的轨迹比难以区分的纹理特征更可靠。即使是由于遮挡或人为探测失败导致某摄像头的轨迹被“破坏”，在跨摄像头ReID的步骤中，也可以根据其他摄像头更完整的轨迹将其破坏的轨迹连接起来。相对于在闭塞前后强制连接可能属于同一个人的两条轨迹或其他类型的故障，本方法仅追求更好的单目跟踪性能，可以获得更好、更可靠的整体性能。

该方法可分为三个步骤:首先，利用训练好的姿态估计神经网络检测每台摄像机捕捉到的每一帧图像中工作人员的姿态;然后筛选出姿态置信度得分高的工作人员，根据每个人脚的图像坐标和预估的图像平面到世界地平面的单应性矩阵，估计和跟踪每个人在手术室中的位置;最后，我们设计了一种聚类算法，重新识别所有摄像机中被检测到的工作人员的轨迹，从而获得手术室中所有工作人员的完整轨迹。

#### 方法

由于手术室场景的特殊性，我们很难用端到端模型解决跟踪和ReID问题;因此，根据其特点，我们建立了一个包含三个模型的框架，逐步完成整个任务。方法流程如图2所示。利用估计的姿态和边界框分别生成所有摄像机的几段轨迹，然后结合所有摄像机的结果连接并重新识别得到的破碎轨迹。

![image-20230124220825454](../images/image-20230124220825454-16745703020465.png)

##### 3.1 姿态估计和检测框

人体姿态估计的研究在计算机视觉领域已流行多年[27-29]。在本文中，我们使用了一种成熟且流行的姿态估计神经网络AlphaPose[27]。对于每一个被检测到的人，AlphaPose不仅给出一套完整的带有置信度分数的姿态关键点，还给出了整个姿态及其包围框的置信度分数。通过获得的信息，我们能够估计每个手术成员在手术室中的位置，并在后续步骤中提取他们的图像特征。

##### 3.2 单目跟踪

因此，受Trackpy[30]的启发，我们设计了一种简洁可靠的方法，在单目跟踪的步骤中利用每个人的位置。首先，从所有检测到的姿态中筛选出可用的姿态，删除那些姿态信心分数小于T11或脚踝信心分数都小于T12的姿态。然后，估计每个筛选出来的手术成员的位置，并将其映射到世界地平面上，我们估计其在图像坐标系中的位置，Cp = (xp, yp)，其两个脚踝坐标在同一帧中，这意味着我们利用一个人的两个脚踝的平均坐标来表示他们的位置:![image-20230124221312362](../images/image-20230124221312362-16745703216817.png)

，其中Cla和Cra分别表示左右脚踝的坐标，然后我们将Cp映射到世界地平面上，使用预先估计的摄像机单应性矩阵H: ![image-20230124221340476](../images/image-20230124221340476-16745703326399.png)

其中(Xp, Yp)表示这个人在地坐标系中的坐标。

最后，我们逐帧跟踪每个筛选的手术成员，如果他们在当前帧和下一帧的位置距离小于预先设定的阈值T13(人在地坐标系中可以跑的最大距离)，则在下一帧中跟踪他们。此外，为了处理某人的姿势可能在某些帧中丢失或被过滤掉的情况，我们设置了另一个参数T14，称为“记忆帧数”，这意味着我们考虑到一个人可能会丢失几帧，然后再次出现的可能性，我们保留消失的外科成员的跟踪，并在他们最后一次出现后保留他们的id，最多保留一些帧数。通过这种方法，我们获得了每个摄像机的所有手术成员的初始轨迹。

##### 3.3 相机间重识别

由于闭塞和一些其他干扰，获得的轨迹将被分成几个段为每个手术成员如上所述。在单目跟踪中，这个问题很难解决。幸运的是，在手术室场景中放置多个摄像机是很方便的，这意味着我们可以通过其他摄像机更完整的轨迹来克服这些挑战。我们引入了基于密度的空间聚类方法(DBSCAN[31])来总结不同摄像机的轨迹，为属于同一人的摄像机分配相同的ID。


原始DBSCAN的思想非常简洁:它从一个没有访问过的任意核心点开始;检索这个点的e邻域，如果它包含足够多的点，则启动一个集群;否则，这个点被标记为噪声。受此思想启发，我们设计了我们的聚类算法:在原始的DBSCAN中，将核心对象定义为其邻域内的高密度点，基于轨迹的完整性，我们将时间长度(单位:帧)大于T21的轨迹定义为我们的案例中的核心对象;对于核心轨迹p，如果p与另一个轨迹q的平均距离小于T22，且p与q的平均目标框相似度(本文采用直方图相关系数)大于T23，则认为q是p的邻域对象。对于聚类后标记为“噪声”的轨迹，我们根据平均距离和平均包围盒相似度为每个“噪声”轨迹寻找最可能的聚类。此外，为了避免逻辑错误，对应于同一行人并来自同一摄像机的轨迹不应该在时域重叠，因为行人只能在一个摄像机帧中出现一次。最后，我们获得了所有检测到的手术成员和对应的轨迹，每个摄像机的id。
